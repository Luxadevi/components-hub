name: scrape
run-name: Scrape components and write to file
on: [push]
  #schedule:
  #  - cron: "0 0 * * *" #runs at 00:00 UTC everyday
jobs:
  build:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo content
        uses: actions/checkout@v2 # checkout the repository content to github runner.
      - name: Setup python
        uses: actions/setup-python@v2
        with:
          python-version: 3.9 #install the python needed
      - name: Install pipenv
        run: |
          python -m pip install --upgrade pipenv wheel
      - name: Use cached dependencies if available
        id: cache-pipenv
        uses: actions/cache@v1
        with:
          path: ~/.local/share/virtualenvs
          key: ${{ runner.os }}-pipenv-${{ hashFiles('**/Pipfile.lock') }}
      - name: Install dependencies
        if: steps.cache-pipenv.outputs.cache-hit != 'true'
        run: |
          pipenv install
      - name: Execute scraper script # run the run.py to get the latest data
        run: |
          pipenv run python scraper.py
        #env:
        #  key: ${{ secrets.key }} # if run.py requires passwords..etc, set it as secrets